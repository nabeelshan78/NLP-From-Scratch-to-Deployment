{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bbadeba2",
   "metadata": {},
   "source": [
    "# **From Dictionary-Based Translation to Attention Mechanisms**\n",
    "\n",
    "This notebook walks through the progression from a **basic dictionary lookup translation system** to a **parallelized attention-based approach**, inspired by Transformer models.\n",
    "\n",
    "- **Basic word translation** using a hardcoded dictionary.\n",
    "- **Tokenization** of text into words.\n",
    "- **Error handling** with fuzzy matching (Levenshtein distance) for misspelled or missing words.\n",
    "- **Vocabulary creation** and **one-hot encoding**.\n",
    "- Representing a translation dictionary with **matrix multiplication**.\n",
    "- **Decoding** one-hot vectors back into words.\n",
    "- Introduction to the **softmax-based attention mechanism**:\n",
    "  - Scaled dot-product attention.\n",
    "  - Transition from sequential to **parallelized translation**.\n",
    "- How these steps mirror components in **modern neural machine translation** systems.\n",
    "\n",
    "1. A naive dictionary translator.\n",
    "2. A matrix-based translator.\n",
    "3. An attention-based translator that processes entire sentences in parallel.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "392417b2-8a30-4b6a-be93-0226b03407db",
   "metadata": {},
   "source": [
    "### Importing required libraries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9d8a4fdb-4e33-455c-908a-10f552681266",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from Levenshtein import distance\n",
    "\n",
    "# suppress warnings\n",
    "def warn(*args, **kwargs):\n",
    "    pass\n",
    "import warnings\n",
    "warnings.warn = warn\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d069b094-63ac-43cc-baad-7581a03e34ee",
   "metadata": {},
   "source": [
    "## Translation\n",
    "\n",
    "- A `dictionary` is defined, mapping French words to their English equivalents, forming the basis of translation logic.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ba260267-16ef-40f5-b22b-dfb200014647",
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary = {\n",
    "    'le': 'the',\n",
    "    'chat': 'cat',\n",
    "    'est': 'is',\n",
    "    'sous': 'under',\n",
    "    'la': 'the',\n",
    "    'table': 'table'\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e9d05a9-09bb-4c4d-ae93-8fc1cc483896",
   "metadata": {},
   "source": [
    "- The `tokenize` function is responsible for breaking down a sentence into individual words.\n",
    "- The `translate` function uses this `tokenize` function to split the input sentence and then translates each word according to the dictionary. The translated words are concatenated to form the output sentence.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "472c1f0b-0de3-41ee-b31c-03611490dc52",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(text):\n",
    "    return text.split()\n",
    "\n",
    "\n",
    "def translate(sentence):\n",
    "    out = ''\n",
    "    for token in tokenize(sentence):\n",
    "        out += dictionary[token] + ' '\n",
    "    return out.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "69a66399-633a-4b9e-a3ac-e799c633ff6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'the cat is under the table'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "translate(\"le chat est sous la table\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac757268-c7cc-45b3-8867-c263ece29d85",
   "metadata": {},
   "source": [
    "### Improvement: What if the 'key' is not in the dictionary?\n",
    "\n",
    "- **find_closest_key Function**: This function find the closest key in the dictionary to a given query word. It uses the **Levenshtein distance** (a measure of the difference between two sequences) to find the dictionary key with the minimum distance to the query, suggesting a similar word if an exact match isn't found.\n",
    "\n",
    "A simple form of error handling and fuzzy matching in translation systems, allowing for more flexible and fault-tolerant translations.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0ea2a6c4-00b4-4fd5-bc17-135c351436b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_closest_key(query):\n",
    "    \"\"\"\n",
    "    The function computes the Levenshtein distance between the query and each key in the dictionary.\n",
    "    The Levenshtein distance is a measure of the number of single-character edits required to change one word into the other.\n",
    "    \"\"\"\n",
    "    closest_key, min_dist = None, float('inf')\n",
    "    for key in dictionary.keys():\n",
    "        dist = distance(query, key)\n",
    "        if dist < min_dist:\n",
    "            min_dist, closest_key = dist, key\n",
    "    return closest_key\n",
    "\n",
    "\n",
    "def translate(sentence):\n",
    "    \"\"\"\n",
    "    This function tokenizes the input sentence into words and finds the closest translation for each word.\n",
    "    It constructs the translated sentence by appending the translated words together.\n",
    "    \"\"\"\n",
    "    out = ''\n",
    "    for query in tokenize(sentence): \n",
    "        key = find_closest_key(query) \n",
    "        out += dictionary[key] + ' '  \n",
    "    return out.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6d8a6cd4-ad02-4528-9741-5e6f30183da8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'table'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "translate(\"tables\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a48e7bfd-50d6-462e-97ad-9fa6a32a509d",
   "metadata": {},
   "source": [
    "### Define vocabularies\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4143f00c-0eec-4e4b-802c-f17f30dbe177",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary input (6): ['chat', 'est', 'la', 'le', 'sous', 'table']\n",
      "Vocabulary output (5): ['cat', 'is', 'table', 'the', 'under']\n"
     ]
    }
   ],
   "source": [
    "# Create and sort the input vocabulary from the dictionary's keys\n",
    "vocabulary_in = sorted(list(set(dictionary.keys())))\n",
    "print(f\"Vocabulary input ({len(vocabulary_in)}): {vocabulary_in}\")\n",
    "\n",
    "# Create and sort the output vocabulary from the dictionary's values\n",
    "vocabulary_out = sorted(list(set(dictionary.values())))\n",
    "print(f\"Vocabulary output ({len(vocabulary_out)}): {vocabulary_out}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94809c6d-9529-4762-b981-b0f5c72b7623",
   "metadata": {},
   "source": [
    "### Encode tokens using 'one hot' encoding\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e79d5ca6-9255-4351-952d-2eb0255a95fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to convert a list of vocabulary words into one-hot encoded vectors\n",
    "def encode_one_hot(vocabulary):\n",
    "    one_hot = dict()                  # Initialize a dictionary to hold one-hot encodings\n",
    "    LEN = len(vocabulary)             # The length of each one-hot encoded vector will be equal to the vocabulary size\n",
    "    \n",
    "    for i, key in enumerate(vocabulary):\n",
    "        one_hot_vector = torch.zeros(LEN)\n",
    "        one_hot_vector[i] = 1\n",
    "        one_hot[key] = one_hot_vector\n",
    "        print(f\"{key}\\t: {one_hot[key]}\")\n",
    "    \n",
    "    return one_hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0e5acff7-8153-46d8-8050-7cc5f0b00b5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chat\t: tensor([1., 0., 0., 0., 0., 0.])\n",
      "est\t: tensor([0., 1., 0., 0., 0., 0.])\n",
      "la\t: tensor([0., 0., 1., 0., 0., 0.])\n",
      "le\t: tensor([0., 0., 0., 1., 0., 0.])\n",
      "sous\t: tensor([0., 0., 0., 0., 1., 0.])\n",
      "table\t: tensor([0., 0., 0., 0., 0., 1.])\n",
      "====================\n",
      "cat\t: tensor([1., 0., 0., 0., 0.])\n",
      "is\t: tensor([0., 1., 0., 0., 0.])\n",
      "table\t: tensor([0., 0., 1., 0., 0.])\n",
      "the\t: tensor([0., 0., 0., 1., 0.])\n",
      "under\t: tensor([0., 0., 0., 0., 1.])\n"
     ]
    }
   ],
   "source": [
    "one_hot_in = encode_one_hot(vocabulary_in)\n",
    "print('=' * 20)\n",
    "one_hot_out = encode_one_hot(vocabulary_out)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2c3851e-141b-4c0b-9bbc-08ac4b193c3e",
   "metadata": {},
   "source": [
    "### Creating a 'dictionary' using matrix multiplication\n",
    "\n",
    "A representation of dictionary suitable for neural network operations:\n",
    "\n",
    "- **Matrix creation**: Using PyTorch's `torch.stack`, convert the one-hot encoded vectors for both input (`K`) and output (`V`) vocabularies into tensors. `K` is constructed from the input vocabulary's one-hot vectors, and `V` from the output vocabulary's vectors. These tensors can be thought of as a look-up table that our model will use to associate input tokens with output tokens.\n",
    "\n",
    "- Each row in `K` corresponds to a word in the input language represented as a one-hot vector, and each row in `V` corresponds to the respective translated word in the output language.\n",
    "\n",
    "- **Query example**: An example shows how to use matrix operations to find a translation. Look up the one-hot vector for the word \"sous\" from the input vocabulary (`q`). Then demonstrate how to find its corresponding translation by performing matrix multiplication with the transpose of `K` (i.e., `q @ K.T`) to identify the index and then use that index to select the relevant row from `V`. This process mimics the lookup."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "46f276de-0e45-4e98-a9ff-adab3cb8376c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0., 0., 1., 0., 0.],\n",
      "        [1., 0., 0., 0., 0., 0.],\n",
      "        [0., 1., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 1., 0.],\n",
      "        [0., 0., 1., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 1.]])\n"
     ]
    }
   ],
   "source": [
    "K = torch.stack([one_hot_in[k] for k in dictionary.keys()])\n",
    "print(K)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9569559c-d0cf-48a1-8203-9dd2973ac762",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0., 0., 1., 0.],\n",
      "        [1., 0., 0., 0., 0.],\n",
      "        [0., 1., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 1.],\n",
      "        [0., 0., 0., 1., 0.],\n",
      "        [0., 0., 1., 0., 0.]])\n"
     ]
    }
   ],
   "source": [
    "V = torch.stack([one_hot_out[k] for k in dictionary.values()])\n",
    "print(V)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6ea4092-caa5-44b2-ac89-fb11991b587b",
   "metadata": {},
   "source": [
    "look up a translation for a given word using matrix operations\n",
    "we take the one-hot representation of 'sous' from the input vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9ce9b23b-8dcf-4614-a4bd-723b70beef75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query token : tensor([0., 0., 0., 0., 1., 0.])\n"
     ]
    }
   ],
   "source": [
    "q = one_hot_in['sous']\n",
    "print(\"Query token :\", q)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5420bca3-62d9-4780-ade2-09039fbd4578",
   "metadata": {},
   "source": [
    "Select the corresponding key vector in K (input dictionary matrix) using matrix multiplication. This operation gives us the index where 'sous' would be '1' in the one-hot encoded input matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1bc6fdf7-4c3a-4ce7-a85d-54956742a97c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Select key (K) : tensor([0., 0., 0., 1., 0., 0.])\n"
     ]
    }
   ],
   "source": [
    "print(\"Select key (K) :\", q @ K.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "061ab196-6f5e-46a5-900c-62e88a8e9609",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9d00dcc4-44ad-45ac-b899-b240762aab70",
   "metadata": {},
   "source": [
    "Use the index found from the key selection to find the corresponding value vector in V (output dictionary matrix). This operation selects the row from V that is the translation of 'sous' in the output vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f063b5cd-1d5a-4996-a23b-1b41bd68e60a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Select value (V): tensor([0., 0., 0., 0., 1.])\n"
     ]
    }
   ],
   "source": [
    "print(\"Select value (V):\", q @ K.T @ V)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9fc8aed-6e14-4db0-8313-8876bfbd81a1",
   "metadata": {},
   "source": [
    "### Decode one-hot vector\n",
    "The `decode_one_hot` function is used to decode a one-hot encoded vector back into the corresponding token (word). It does this by finding the token whose one-hot representation has the highest cosine similarity with the given vector, which is effectively just the dot product due to the nature of one-hot vectors.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "006d41f9-8ab7-49b1-91ae-11ad83cf3b18",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_one_hot(one_hot, vector):\n",
    "    best_key, best_cosine_sim = None, 0\n",
    "    for k, v in one_hot.items():\n",
    "        cosine_sim = torch.dot(vector, v)\n",
    "        if cosine_sim > best_cosine_sim:\n",
    "            best_cosine_sim, best_key = cosine_sim, k\n",
    "    return best_key"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f74a75c-8780-49a9-a187-deb4d140ed33",
   "metadata": {},
   "source": [
    "The operation $q \\cdot K^T \\cdot V$ allows us to build a dictionary-like structure from a set of vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fa5cb04f-6e17-4da3-b06e-dccd8d913c8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chat  =  cat\n",
      "est  =  is\n",
      "la  =  the\n",
      "le  =  the\n",
      "sous  =  under\n",
      "table  =  table\n"
     ]
    }
   ],
   "source": [
    "for k, v in one_hot_in.items():\n",
    "    print(k, \" = \", decode_one_hot(one_hot_out, one_hot_in[k] @ K.T @ V))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f7bf8a1-ae58-4b78-a7b5-c107a34d3757",
   "metadata": {},
   "source": [
    "### Matrix-based translate function\n",
    "The `translate` function now leverages matrix operations to perform the translation. For each token in the input sentence, it finds its one-hot vector, multiplies it with the matrices `K.T` and `V` to find the corresponding one-hot vector in the output vocabulary, and then decodes this vector to get the translated word.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "de896d37-d36f-4576-bfb9-0ebb550a1a80",
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate(sentence):\n",
    "    sentence_out = ''\n",
    "    for token_in in tokenize(sentence):\n",
    "        q = one_hot_in[token_in]                      # Find the one-hot vector for the token\n",
    "        out = q @ K.T @ V                             # Multiply with the input and output matrices to find the translation\n",
    "        token_out = decode_one_hot(one_hot_out, out)  # Decode the output one-hot vector to a token\n",
    "        sentence_out += token_out + ' '               # Append the translated token to the output sentence\n",
    "    return sentence_out.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9d4148f5-7315-4c15-9339-a01af3787803",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'the cat is under the table'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "translate(\"le chat est sous la table\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a6f5d1c-ce55-460f-b1fb-4d87fb9f8344",
   "metadata": {},
   "source": [
    "**This enhanced approach shows how neural network models can translate languages by representing the translation dictionary as matrices and using vector operations.**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54d6875a-3c08-40be-b2e9-3517a718f1b8",
   "metadata": {},
   "source": [
    "**Lets go towards the implementation of \"Attention\" in neural networks:**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dff0590e-cc5d-4859-a764-572281dfcf65",
   "metadata": {},
   "source": [
    "### Softmax function for similarity\n",
    "Similar tokens will have similar vectors, and a softmax function is applied to the output of the matrix multiplication of the query vector `q` and the transpose of the matrix `K`. The softmax function converts these values into probabilities, emphasizing the most similar token while still considering the others.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bfbf28e4-1926-46af-aa7a-33861229ce2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E_{table} =  tensor([0., 0., 0., 0., 0., 1.])\n"
     ]
    }
   ],
   "source": [
    "print('E_{table} = ', one_hot_in['table'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1111744-eebd-45b1-aceb-2393cc5d354c",
   "metadata": {},
   "source": [
    "New equation is:\n",
    "$$\n",
    "softmax(q \\cdot K^T) \\cdot V\n",
    "$$\n",
    "\n",
    "Let's adjust by the dimensionality of the query vector\n",
    "\n",
    "$$\n",
    "softmax\\left( \\frac{q \\cdot K^T}{\\sqrt{d}} \\right) \\cdot V\n",
    "$$  \n",
    "\n",
    "\n",
    "\n",
    "Scaled Dot-Product Attention in Transformers - and it’s there to keep the numbers stable during training.\n",
    "\n",
    "    Q = query matrix\n",
    "    K = key matrix\n",
    "    V = value matrix\n",
    "    d = dimension of each attention head (head_size)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efadd2e8-fbc1-4601-bac4-a7c119f8d50c",
   "metadata": {},
   "source": [
    "### Translation with attention mechanism\n",
    "- The progression from simple look-up-based translation to an attention-based approach, a key component of modern neural translation models.\n",
    "\n",
    "The `translate` function is modified to use the softmax function as a way of applying attention. It first finds the one-hot vector for the token, then applies the softmax function to the dot product of `q` and `K.T`, scales it by the square root of the dimensionality (for normalization purposes), and finally multiplies this by `V` to get the output vector.  \n",
    "\n",
    "    The softmax function is used to calculate a weighted sum of the V vectors, focusing on the most relevant vector for translation.\n",
    "    The result is a blend of value vectors, with the most relevant ones contributing more to the output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4f3bd80a-3b41-428c-a84e-7318bef74f2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'the cat is under the table'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def translate(sentence):\n",
    "    sentence_out = '' \n",
    "    for token_in in tokenize(sentence):\n",
    "        q = one_hot_in[token_in]              # Get the one-hot vector for the current token\n",
    "        # Apply softmax to the scaled dot product of q and K.T, then multiply by V\n",
    "        # This selects the most relevant translation vector from V\n",
    "        out = torch.softmax(q @ K.T, dim=0) @ V\n",
    "        token_out = decode_one_hot(one_hot_out, out)  # Decode the output vector to a token\n",
    "        sentence_out += token_out + ' '  \n",
    "    return sentence_out.strip()\n",
    "\n",
    "translate(\"le chat est sous la table\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ef2a7ad-e36b-41fd-ba90-48e51d44c1c3",
   "metadata": {},
   "source": [
    "the attention mechanism implemented using softmax works as intended.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75fdeeb6-8a7b-4f1a-b060-1015dd628ce5",
   "metadata": {},
   "source": [
    "**Improvement in the translation process by handling all queries in parallel:**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06bb166e-864b-4bc8-86ad-128dc6e70313",
   "metadata": {},
   "source": [
    "### Creating the 'Q' matrix\n",
    "The matrix `Q` is constructed by stacking the one-hot encoded vectors of all tokens in the input sentence. This parallelizes the process of preparing the query vectors, which is more efficient than doing it sequentially."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "618e1bda-8e37-4b1e-a38d-0675cd8b5aa0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0., 0., 1., 0., 0.],\n",
      "        [1., 0., 0., 0., 0., 0.],\n",
      "        [0., 1., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 1., 0.],\n",
      "        [0., 0., 1., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 1.]])\n"
     ]
    }
   ],
   "source": [
    "# The sentence we want to translate\n",
    "sentence = \"le chat est sous la table\"\n",
    "\n",
    "# Stack all the one-hot encoded vectors for the tokens in the sentence to form the Q matrix\n",
    "Q = torch.stack([one_hot_in[token] for token in tokenize(sentence)])\n",
    "\n",
    "print(Q)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f470608-88db-4974-8156-93e7dddc8fe4",
   "metadata": {},
   "source": [
    "$$\n",
    "Attention(Q, K, V) = softmax\\left( \\frac{Q \\cdot K^T}{\\sqrt{d}} \\right) V\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b0fc910b-ee43-4799-bbba-78d807b1e80e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0., 0., 0., 0., 0.],\n",
       "        [0., 1., 0., 0., 0., 0.],\n",
       "        [0., 0., 1., 0., 0., 0.],\n",
       "        [0., 0., 0., 1., 0., 0.],\n",
       "        [0., 0., 0., 0., 1., 0.],\n",
       "        [0., 0., 0., 0., 0., 1.]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Q @ K.T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49edb285-b428-4ec9-b1cb-3135206ec98e",
   "metadata": {},
   "source": [
    "### Updated translate function\n",
    "The `translate` function is revised to use matrix multiplication across the entire sentence. Instead of translating word by word, it now uses the \"Q\" matrix to perform the operation in parallel for all words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8b60b07b-963c-4b4f-bd7e-82ae764cafc7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'the cat is under the table'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def translate(sentence):\n",
    "    \"\"\"\n",
    "    Translate a sentence using matrix multiplication in parallel.\n",
    "    This function replaces the iterative approach with a single matrix multiplication step,\n",
    "    applying the attention mechanism across all tokens at once.\n",
    "    \"\"\"\n",
    "    # Tokenize the sentence and stack the one-hot vectors to form the Q matrix\n",
    "    Q = torch.stack([one_hot_in[token] for token in tokenize(sentence)])\n",
    "    \n",
    "    # Apply softmax to the dot product of Q and K.T and multiply by V\n",
    "    # This will give us the output vectors for all tokens in parallel\n",
    "    out = torch.softmax(Q @ K.T, 0) @ V\n",
    "    \n",
    "    # Decode each one-hot vector in the output to the corresponding token\n",
    "    # And join the tokens to form the translated sentence\n",
    "    return ' '.join([decode_one_hot(one_hot_out, o) for o in out])\n",
    "    \n",
    "# Test the function to ensure it produces the correct translation\n",
    "translate(\"le chat est sous la table\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc51b39f-508b-4df5-a82b-d40c6203767c",
   "metadata": {},
   "source": [
    "- **Efficiency improvement**: By applying operations to the entire sentence at once, this approach simulates a key aspect of the actual attention mechanism used in neural networks, which is processing multiple components of input data in parallel for faster computation.\n",
    "\n",
    "- **Test output**: The updated function correctly translates the French sentence \"le chat est sous la table\" to \"the cat is under the table\", confirming that the parallelization works effectively.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a17f3bf-095a-4d81-a326-def337857fa5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
